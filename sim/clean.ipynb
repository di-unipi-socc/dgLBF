{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "\n",
    "Get a dataframe for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba = pd.read_parquet(\"results/BA/results.parquet\")\n",
    "df_ba_more = pd.read_parquet(\"results/BA-more/results.parquet\")\n",
    "df_ba_norel = pd.read_parquet(\"results/BA-norel/results.parquet\")\n",
    "df_er = pd.read_parquet(\"results/ER07/results.parquet\")\n",
    "df_er_more = pd.read_parquet(\"results/ER07-more/results.parquet\")\n",
    "df_er_norel = pd.read_parquet(\"results/ER07-norel/results.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    \"ba\": df_ba,\n",
    "    \"er\": df_er,\n",
    "    \"ba_more\": df_ba_more,\n",
    "    \"er_more\": df_er_more,\n",
    "    \"ba_norel\": df_ba_norel,\n",
    "    \"er_norel\": df_er_norel,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ba (10500, 28)\n",
      "er (10500, 28)\n",
      "ba_more (2100, 28)\n",
      "er_more (2100, 28)\n",
      "ba_norel (4200, 28)\n",
      "er_norel (4200, 28)\n"
     ]
    }
   ],
   "source": [
    "for a, df in dfs.items():\n",
    "    print(a, df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    if name.startswith(\"ba\"):\n",
    "        df[\"Topology\"] = \"Barabasi-Albert\"\n",
    "    elif name.startswith(\"er\"):\n",
    "        df[\"Topology\"] = \"Erdos-Renyi\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown topology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unused columns (w.r.t further analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_get = ['Output', 'Inferences', 'Time', 'Seed', 'RepProb', 'Infr', 'Flows',\n",
    "       'Nodes', 'Edges', 'Topology', 'timestamp', 'time_this_iter_s', 'time_total_s']\n",
    "\n",
    "for df in dfs.values():\n",
    "    df.drop(columns=[col for col in df.columns if col not in cols_to_get], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the types of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs.values():\n",
    "    df['Output'] = df['Output'].apply(lambda x: 'success' if x not in ['no_result', 'timeout'] else x)\n",
    "    df[\"Inferences\"] = df[\"Inferences\"].replace({\"None\": 0})\n",
    "\n",
    "    df[\"Inferences\"] = df[\"Inferences\"].astype(np.int64)\n",
    "    df[\"Time\"] = df[\"Time\"].astype(np.float64)\n",
    "    df[\"Seed\"] = df[\"Seed\"].astype(np.int32)\n",
    "    df[\"RepProb\"] = df[\"RepProb\"].astype(np.float64)\n",
    "    df[\"Flows\"] = df[\"Flows\"].astype(np.int32)\n",
    "    df[\"Nodes\"] = df[\"Nodes\"].astype(np.int16)\n",
    "    df[\"Edges\"] = df[\"Edges\"].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics on the number of _success_, _timeout_ and _no_result_ labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ba 5077 5223 200\n",
      "er 6978 3519 3\n",
      "ba_more 77 1983 40\n",
      "er_more 656 1444 0\n",
      "ba_norel 3830 370 0\n",
      "er_norel 4200 0 0\n"
     ]
    }
   ],
   "source": [
    "for name, df in dfs.items():\n",
    "    print(name, len(df[df[\"Output\"] == \"success\"]), len(df[df[\"Output\"] == \"timeout\"]), len(df[df[\"Output\"] == \"no_result\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the dataset into two dataframes: one for the _original_ and one for the _modified/new_ methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged = pd.concat(list(dfs.values()))\n",
    "# df_sorted = df_merged.sort_index().sort_values(by=[\"Topology\", \"Seed\", \"RepProb\", \"Nodes\", \"Flows\"])\n",
    "# df_sorted.to_parquet(\"results/all.parquet\")\n",
    "\n",
    "df_merged_norel = pd.concat([df_ba_norel, df_er_norel])\n",
    "df_merged_norel.drop(columns=[\"RepProb\"])\n",
    "df_sorted_norel = df_merged_norel.sort_index().sort_values(by=[\"Topology\", \"Seed\", \"Nodes\", \"Flows\"])\n",
    "df_sorted_norel.to_parquet(\"results/all-norel.parquet\")\n",
    "\n",
    "df_merged = pd.concat([df_ba, df_er, df_ba_more, df_er_more])\n",
    "df_sorted = df_merged.sort_index().sort_values(by=[\"Topology\", \"Seed\", \"RepProb\", \"Nodes\", \"Flows\"])\n",
    "df_sorted.to_parquet(\"results/all.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
